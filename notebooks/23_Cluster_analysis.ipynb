{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb62a90-46da-4198-aeef-6e2f7592c91c",
   "metadata": {},
   "source": [
    "# Análisis de conglomerados (Cluster analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096a230-b7a2-452d-ba65-abbf0dc94503",
   "metadata": {},
   "source": [
    "*¿Para qué se utiliza?*\n",
    "El análisis de conglomerados es una técnica estadística exploratoria que tiene como objetivo agrupar elementos similares en conglomerados (clusters). Cada conglomerado está formado por individuos u objetos que presentan características similares entre sí, pero diferentes respecto a los elementos de otros grupos.\n",
    "Esta técnica es especialmente útil en contextos donde no se conocen previamente las categorías, como en la segmentación de mercados, clasificación de clientes, análisis de perfiles o agrupación de productos.\n",
    "\n",
    "*Tipo de variables consideradas:*\n",
    "El análisis puede aplicarse a variables cuantitativas, cualitativas o mixtas, dependiendo del método utilizado. En la práctica, lo más común es trabajar con variables cuantitativas estandarizadas.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "El análisis de conglomerados busca formar grupos homogéneos basándose en medidas de distancia o similitud entre observaciones. Cuanto menor sea la distancia entre dos elementos, mayor será su similitud.\n",
    "Principales métodos de agrupamiento:\n",
    "- Método jerárquico (aglomerativo o divisivo):\n",
    "    - Construye una jerarquía de grupos mediante un dendrograma.\n",
    "    - No requiere definir el número de grupos de antemano.\n",
    "    - Útil en muestras pequeñas o para visualización exploratoria.\n",
    "- Método de K-medias (k-means):\n",
    "    - Requiere especificar el número de conglomerados (k) antes del análisis.\n",
    "    - Asigna cada observación al grupo cuyo centroide esté más cerca.\n",
    "    - Ideal para grandes conjuntos de datos y resultados reproducibles.\n",
    "- Métodos alternativos:\n",
    "    - K-medoides, DBSCAN, análisis de conglomerados mixtos, entre otros, se utilizan en situaciones más complejas o cuando hay ruido en los datos.\n",
    "\n",
    "*Selección y preparación de variables*\n",
    "Una fase crítica en el análisis de conglomerados es la selección de variables, ya que estas definen la base para medir similitud entre elementos.\n",
    "\n",
    "Recomendaciones:\n",
    "- Elegir variables relevantes y significativas para el fenómeno que se desea estudiar.\n",
    "- Evitar incluir demasiadas variables, ya que esto puede dificultar la interpretación y disminuir la calidad de la segmentación (problema de la \"maldición de la dimensionalidad\").\n",
    "- Evitar incluir variables altamente correlacionadas (por ejemplo, coeficiente de correlación r>0.90r > 0.90r>0.90), ya que pueden distorsionar el análisis.\n",
    "- Si existen muchas variables correlacionadas, se recomienda aplicar un análisis factorial o de componentes principales (PCA) y usar los puntuaciones factoriales o componentes como insumo para el análisis de conglomerado\n",
    "\n",
    "*Supuestos y características*\n",
    "- No requiere variables dependientes: El análisis es puramente exploratorio, sin hipótesis a priori.\n",
    "- No requiere distribución normal ni varianzas homogéneas.\n",
    "- Escala de medición: Para métodos basados en distancias, las variables deben estar en la misma escala, por lo que es habitual estandarizarlas (media = 0, desviación estándar = 1) antes del análisis.\n",
    "- Representatividad: Aunque el análisis es exploratorio, los resultados serán más útiles si la muestra es representativa del universo de estudio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062eaba-ca82-4161-a8d8-b406c06a1ca6",
   "metadata": {},
   "source": [
    "## Práctica 1: Método jerárquico\n",
    "Aplicaremos el método jerárquico a un conjunto de datos. Hay dos paquetes muy utilizados: scikitlearn y scipy, por su facilidad, utilizaremos el segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b3048-c9f4-4f12-ab08-36fdac10f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con Windows para K-means, limitar el uso de núcleos del procesador\n",
    "#import os\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3180c2-c3e4-4d96-a740-99f06ef60e00",
   "metadata": {},
   "source": [
    "Carga el archivo de ejemplo `cerveza.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662af88-2ae7-4803-8cc6-a9b1a475f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('https://github.com/adan-rs/amd/raw/main/data/cerveza.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9cbbd-4aed-4773-b0b2-b874cb811e8e",
   "metadata": {},
   "source": [
    "En este ejemplo no es necesario pero es conveniente realizar un análisis exploratorio y evaluar la presencia de datos nulos, datos perdidos, datos atípicos y datos repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b13a5-8156-4ddc-8e65-4f8166650110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ba199-4f42-4e25-8e8c-c299c5d9bfae",
   "metadata": {},
   "source": [
    "**Selección de variables**: En el análisis de conglomerados, primeramente, se debe decidir qué variables se utilizarán. Es recomendable no utilizar demasiadas variables debido a que se incrementa la complejidad en la identificación de los grupos. Es recomendable además que no estén altamente correlacionadas (p. ej. un coeficiente de correlación mayor a 0.90). En caso de que se tengan muchas variables correlacionadas entre sí, se puede realizar previamente un análisis factorial y utilizar los puntajes factoriales para el análisis de conglomerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688dc72-09ab-429f-8e6b-de587d7888b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cuant = ['Calorias', 'Alcohol', 'Contenido', 'Costo100ml']\n",
    "matriz_corr = df[var_cuant].corr()\n",
    "matriz_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40d48a-b3c6-43e5-8947-212745b84c4e",
   "metadata": {},
   "source": [
    "Para este ejemplo, debido a que la variable “Calorías” y “Porcentaje de alcohol” tienen un coeficiente de correlación de 0.909, de ambas se utilizará solamente “Calorías”. Adicionalmente se considerará la variable de “Costo100ml”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2ed2a-dbfd-4d4a-94f9-e12b09e7783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Calorias', 'Costo100ml']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72610d7-7a97-49ad-811c-c72ef387dacf",
   "metadata": {},
   "source": [
    "**Estandarizar variables**: Es importante que las variables puedan ser comparables, por lo tanto, se recomienda estandarizar las variables. *StandarScaler* transforma la variable a una distribución con media cero y desviación estándar igual a uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2188502-cfda-4d9b-a680-fd2672509515",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8ab8b-fccf-41af-bbcd-59e3ef6e4612",
   "metadata": {},
   "source": [
    "**Seleccionar método**. Aplicaremos la función *linkage** de la biblioteca *scipy*. Se pueden definir varios parámetros, es decir, valores que controlan el comportamiento del algoritmo:\n",
    "1. *metric*: entre las principales medidas están\n",
    "    - *euclidean*: es la predeterminada y la más común. Corresponde a la raíz cuadrada de la suma de las diferencias al cuadrado de los valores de las variables.\n",
    "    - *cityblock*: Utiliza la suma de los valores absolutos de las diferencias de los valores de las variables.\n",
    "\n",
    "2. *linkage*: es el método que se utilizará para determinar la similitud entre pares de objetos. Entre otros están:\n",
    "    - *ward*: fusiona aquellos dos grupos que menos incrementen la suma de los cuadrados de las desviaciones.\n",
    "    - *average*: es el promedio de las distancias entre todos los pares de ambos grupos\n",
    "    - *complete*: utiliza las distancias máximas entre cualquier par de elementos en dos grupos\n",
    "    - *single*: utiliza la distancia entre las observaciones más cercanas entre cualquier par de elementos en dos grupos.\n",
    "  \n",
    "Si se desea obtener conglomerados (*clusters*) de tamaños similares y no existen valores atípicos, se recomienda utilizar el método de Ward. Se recomienda no mezclar variables cuantitativas con cualitativas, en caso de hacerlo, utilizar una métrica apropiada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906682f-292f-412e-a925-f076f0991a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniones = linkage(X_std, method='ward', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58105e3-4d30-41ca-b793-04c3ce302ad2",
   "metadata": {},
   "source": [
    "Es posible obtener el historial de cómo se fueron realizando los agrupamientos, sin embargo, por practicidad es preferible el uso del dendrograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126457ff-ac2c-40f1-81fc-c0557bbea982",
   "metadata": {},
   "outputs": [],
   "source": [
    "historial_uniones = pd.DataFrame(uniones, columns=['Cluster 1', 'Cluster 2', \n",
    "                                           'Distancia', 'Observaciones'])\n",
    "historial_uniones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e166ba-95a7-495e-9dab-89dba1afc955",
   "metadata": {},
   "source": [
    "Para visualizar el dendrograma, utilizamos la función  `dendrogram()` junto con `pyplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98e90c-f444-4b51-8c50-bbdc1b5e2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('Dendrograma Jerárquico')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(uniones, orientation='right', labels=df['Cerveza'].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b18a29-5aa2-4b40-9653-5d8e1b843600",
   "metadata": {},
   "source": [
    "Las líneas horizontales representan distancias, mientras que las líneas verticales sirven para unir las observaciones. A partir de este gráfico podemos definir los clusters (en diferente color)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ed273-a028-402a-8975-e4e6e8543636",
   "metadata": {},
   "source": [
    "## Práctica 2: Método de k-medias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15f9dd-6425-4068-9180-d8781853c723",
   "metadata": {},
   "source": [
    "Repetiremos el ejercicio utilizando el método jerárquico. El algoritmo de este método no está basado en distancias sino en la variación dentro de los conglomerados, por lo tanto, no se requiere establecer una medida de distancia. El proceso inicia asignando aleatoriamente los elementos a cierto número de conglomerados. Los elementos son sucesivamente reasignados a otros conglomerados para minimizar la variación dentro de cada conglomerado.\n",
    "\n",
    "El método de k-medias se considera superior a los métodos jerárquicos (debido a que es menos afectado por valores atípicos) y es más conveniente para muestras grandes. Es recomendable utilizarlo sólo con variables cuantitativas o en algunos casos con variables ordinales.  El inconveniente principal es que se debe especificar cuántos conglomerados se van a utilizar, por ello, muchos investigadores recomiendan previamente utilizar el método jerárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85df0d-401e-4d75-b74f-2c7a609353af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1830c-36f8-4af7-9c17-694522be820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar variables\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a4bdb-e0aa-4db2-bcec-ba75894e40b2",
   "metadata": {},
   "source": [
    "En este procedimiento se establece el número de grupos o *clusters* (k). Posteriomente\n",
    "1. Se crean k \"centros\" en ubicaciones aleatorias.\n",
    "2. Para cada observación:\n",
    "    - Se calcula la distancia a los k centros\n",
    "    - La observación es asignada al grupo con el centro más cercano.\n",
    "3. Los centros se mueven al centro de su respectivo grupo.\n",
    "4. Los pasos 2 y 3 se repiten hasta que no existan cambios en la pertenencia.\n",
    "\n",
    "El método de k-medias es apropiado cuando se asume que los grupos tienen forma convexa (p. ej. círculo) y tamaños similares. Si no es el caso, conviene explorar otras metodologías para el análisis de conglomerados. \n",
    "\n",
    "Utilizaremos la función de k-means en scikit-learn. El parámetro más importante es *n_clusters* que indica el número de grupos (k). Otro parámetro es *n_jobs=-1* para utilizar todos los núcleos del procesador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124c883-bc76-4304-b983-6c7983bae081",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "# Crear modelo\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "# Ajustar modelo\n",
    "model = kmeans.fit(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087610a-2401-469d-9026-2d0e8d9c6211",
   "metadata": {},
   "source": [
    "Con `.labels_` se obtiene la clase pronosticada de cada observación, y con `.cluster_centers_` se puede encontrar el centro de cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a72c6-8b87-4834-aab5-5ad3fd569cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = model.labels_\n",
    "centroids = model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020f6f5-af4b-4ba4-b54f-33083b42e596",
   "metadata": {},
   "source": [
    "Conviertiendo el array `centroids` a un dataframe (*¿Cómo interpretas los centroides?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe634d0-51ad-44dc-98f2-ac2163bcaf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centroids = pd.DataFrame(centroids, columns = X.columns)\n",
    "df_centroids['Cluster Name'] = ['Segmento {}'.format(i+1) for i in range(len(df_centroids))]\n",
    "df_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4873d-206f-4c60-802f-5ede7c52f92b",
   "metadata": {},
   "source": [
    "**Opcional**: Como solamente estamos usando dos variables podríamos graficarlo en un plano:\n",
    "- Creamos un *bucle* para cada grupo `for i in range (k)`,\n",
    "- Identificamos las observaciones de cada grupo y las seleccionamos: `cluster_i = np.where(cluster==i)`\n",
    "- Hacemos un diagrama de dispersión `plt.scatter(X_std[cluster_i,0], X_std[cluster_i,1]`\n",
    "- Ubicamos el centroide `plt.scatter(centroids[:,0],centroids[:,-1], marker='*', s=200`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb9da9-72ad-402c-b8ac-0fe2a84b40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (k):\n",
    "    cluster_i = np.where(cluster==i)\n",
    "    plt.scatter(X_std[cluster_i,0], X_std[cluster_i,1])\n",
    "    plt.scatter(centroids[:,0],centroids[:,1], marker='*', s=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13eb58-f8d1-4c99-9f7d-6169f757bb12",
   "metadata": {},
   "source": [
    "*Medida de silueta*\n",
    "\n",
    "La medida de silueta de cohesión y separación es una medida de bondad de ajuste. Un valor menor a 0.20 indica una mala calidad de la solución, un valor superior a 0.5 indica una buena solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e95a0-4b86-46aa-aa0f-e1da491ca9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X_std, cluster) #X_std son los datos y 'cluster' la asignación\n",
    "print('Medida de silueta:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c02176-a53b-4ffb-8e29-e441599ba21d",
   "metadata": {},
   "source": [
    "*Método del codo*\n",
    "\n",
    "Algunos utilizan el método del codo (*elbow method*). En este método se calcula la *inercia* en diferentes valores de *k*. La inercia es la suma de las distancias al cuadrado de cada objeto del cluster a su centroide. Tras graficar estos valores, el punto en el cual cambia la tendencia corresponderá al número apropiado de grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a0366-b786-4fa4-8be7-be55731c0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wss = [] #wss, del inglés Within-Cluster Sum of Squares\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wss.append(kmeans.inertia_)\n",
    "\n",
    "# Crear gráfico\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(range(1, 11), wss)\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fa621-e6ee-4e74-a0b8-61172953f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Segmento'] = cluster\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c8610-4973-4aeb-bdec-1b6146ef02ca",
   "metadata": {},
   "source": [
    "Ejemplo de un reporte de resultados\n",
    ">Se realizó un análisis de conglomerados mediante el algoritmo k-medias (k-means) con el propósito de segmentar a los clientes de una tienda en línea en función de sus comportamientos de compra.\n",
    ">\n",
    ">Las variables utilizadas incluyeron: frecuencia de compra mensual, monto promedio por compra, número de categorías distintas adquiridas, y nivel de satisfacción reportado (escala de 1 a 10). Dado que las variables se encuentran en diferentes escalas, se procedió a estandarizarlas mediante la transformación z-score antes del análisis.\n",
    ">\n",
    ">Para determinar el número óptimo de grupos, se calculó el índice de silueta para valores de k entre 2 y 6. El valor más alto del índice se obtuvo con k = 3 (índice de silueta promedio = 0.51), lo que indica una estructura de conglomerados razonablemente bien definida.\n",
    ">\n",
    ">El análisis identificó tres segmentos de clientes:\n",
    ">- Cluster 1 (35%): compradores frecuentes y altamente satisfechos, con gasto medio-alto y variedad de productos; perfil ideal para programas de lealtad.\n",
    ">- Cluster 2 (40%): compradores ocasionales con bajo gasto y satisfacción moderada; susceptibles a estímulos promocionales.\n",
    ">- Cluster 3 (25%): clientes de alto gasto pero baja frecuencia y baja satisfacción; pueden requerir intervenciones postventa o atención personalizada.\n",
    "Los resultados del análisis permitirán diseñar estrategias diferenciadas de marketing, con mensajes, promociones y ofertas alineadas a las características de cada segmento.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75bb28-688c-4626-b5c8-6fb5d4288753",
   "metadata": {},
   "source": [
    "## Preguntas de autoevaluación\n",
    "\n",
    "**Pregunta 1**. En una empresa de retail, se están explorando diferentes métodos para segmentar a los clientes en grupos con características similares. ¿En cuál de los siguientes escenarios es más apropiado utilizar el método de k-medias (k-means) en lugar del método de clustering jerárquico?\n",
    "Opciones:\n",
    "\n",
    "A) La empresa tiene un pequeño número de clientes (menos de 100) y quiere visualizar la jerarquía completa de agrupaciones posibles, desde un único grupo hasta cada cliente en su propio grupo.\n",
    "\n",
    "B) La empresa tiene una gran cantidad de datos de clientes (más de 10,000) y busca crear rápidamente un número fijo de segmentos, optimizando la homogeneidad dentro de cada grupo.\n",
    "\n",
    "C) La empresa no tiene claro cuántos segmentos debe crear y quiere probar diferentes criterios de enlace para determinar la estructura más adecuada, explorando la posibilidad de subgrupos dentro de grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ffd01-a078-470b-a75b-0253f63c3fde",
   "metadata": {},
   "source": [
    "**Pregunta 2**. Una empresa de marketing digital está desarrollando una estrategia para personalizar campañas publicitarias según el comportamiento de los usuarios en su plataforma. Han realizado un análisis de clustering para segmentar a los usuarios en diferentes grupos, pero ahora necesitan determinar cuántos segmentos utilizar para obtener la mejor separación entre los grupos. Entre las siguientes métricas, ¿cuál es la más útil para evaluar la calidad de los clusters y ayudar a definir el número óptimo de segmentos?\n",
    "\n",
    "A) Distancia euclidiana\n",
    "\n",
    "B) Coeficiente de correlación\n",
    "\n",
    "C) Medida de silueta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086e18e-37be-4072-bf1f-dbb8b623ff9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}